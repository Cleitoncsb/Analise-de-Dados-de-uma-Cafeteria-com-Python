#Este código é uma ferramenta automatizada para scraping (extração) de dados de produtos 
#de uma loja online, especificamente focada em rações para gatos. Ele usa o Selenium para 
#navegar em várias páginas da loja Cobasi, coletando nomes e preços dos produtos. 


from selenium import webdriver
from bs4 import BeautifulSoup
import pandas as pd
import time

# Lista de URLs para visitar
urls = [
    'https://www.cobasi.com.br/c/gatos/racao',
    'https://www.cobasi.com.br/c/gatos/racao?page=2',
    'https://www.cobasi.com.br/c/gatos/racao?page=3',
    # Adicione mais URLs conforme necessário
]

# Inicializando o WebDriver do Safari
driver = webdriver.Safari()

nomes_produtos = []
precos_produtos = []

for url in urls:
    driver.get(url)
    time.sleep(5)  # Esperar para o JavaScript carregar

    soup = BeautifulSoup(driver.page_source, 'html.parser')
    
    # Extração de dados
    produtos = soup.find_all('h3', class_='styles__Title-sc-1ac06td-4 dPsqyZ')
    precos = soup.find_all('span', class_='card-price')

    for produto in produtos:
        nomes_produtos.append(produto.get_text().strip())
    for preco in precos:
        precos_produtos.append(preco.get_text().strip())

driver.quit()

# Criar DataFrame e salvar em Excel
df = pd.DataFrame({
    'Nome do Produto': nomes_produtos,
    'Preço do Produto': precos_produtos
})

df.to_excel('dados_extraidos.xlsx', index=False)
